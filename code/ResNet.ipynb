{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Local\\Continuum\\anaconda3\\envs\\test\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic ResNet model\n",
    "\n",
    "def init_layer(L):\n",
    "    # Initialization using fan-in\n",
    "    if isinstance(L, nn.Conv2d):\n",
    "        n = L.kernel_size[0]*L.kernel_size[1]*L.out_channels\n",
    "        L.weight.data.normal_(0,math.sqrt(2.0/float(n)))\n",
    "    elif isinstance(L, nn.BatchNorm2d):\n",
    "        L.weight.data.fill_(1)\n",
    "        L.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Simple ResNet Block\n",
    "class SimpleBlock(nn.Module):\n",
    "    def __init__(self, indim, outdim, half_res):\n",
    "        super(SimpleBlock, self).__init__()\n",
    "        self.indim = indim\n",
    "        self.outdim = outdim\n",
    "        self.C1 = nn.Conv2d(indim, outdim, kernel_size=3, stride=2 if half_res else 1, padding=1, bias=False)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.BN1 = nn.BatchNorm2d(outdim)\n",
    "        self.C2 = nn.Conv2d(outdim, outdim,kernel_size=3, padding=1,bias=False)\n",
    "        self.BN2 = nn.BatchNorm2d(outdim)\n",
    "\n",
    "        self.parametrized_layers = [self.C1, self.C2, self.BN1, self.BN2]\n",
    "\n",
    "        self.half_res = half_res\n",
    "\n",
    "        # if the input number of channels is not equal to the output, then need a 1x1 convolution\n",
    "        if indim!=outdim:\n",
    "            self.shortcut = nn.Conv2d(indim, outdim, 1, 2 if half_res else 1, bias=False)\n",
    "            self.parametrized_layers.append(self.shortcut)\n",
    "            self.BNshortcut = nn.BatchNorm2d(outdim)\n",
    "            self.parametrized_layers.append(self.BNshortcut)\n",
    "            self.shortcut_type = '1x1'\n",
    "        else:\n",
    "            self.shortcut_type = 'identity'\n",
    "\n",
    "        for layer in self.parametrized_layers:\n",
    "            init_layer(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.C1(x)\n",
    "        out = self.BN1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.C2(out)\n",
    "        out = self.BN2(out)\n",
    "        short_out = x if self.shortcut_type == 'identity' else self.BNshortcut(self.shortcut(x))\n",
    "        out = out + short_out\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# Bottleneck block\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, indim, outdim, half_res):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        bottleneckdim = int(outdim/4)\n",
    "        self.indim = indim\n",
    "        self.outdim = outdim\n",
    "        self.C1 = nn.Conv2d(indim, bottleneckdim, kernel_size=1,  bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.BN1 = nn.BatchNorm2d(bottleneckdim)\n",
    "        self.C2 = nn.Conv2d(bottleneckdim, bottleneckdim, kernel_size=3, stride=2 if half_res else 1,padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(bottleneckdim)\n",
    "        self.C3 = nn.Conv2d(bottleneckdim, outdim, kernel_size=1, bias=False)\n",
    "        self.BN3 = nn.BatchNorm2d(outdim)\n",
    "\n",
    "        self.parametrized_layers = [self.C1, self.BN1, self.C2, self.BN2, self.C3, self.BN3]\n",
    "        self.half_res = half_res\n",
    "\n",
    "\n",
    "        # if the input number of channels is not equal to the output, then need a 1x1 convolution\n",
    "        if indim!=outdim:\n",
    "            self.shortcut = nn.Conv2d(indim, outdim, 1, stride=2 if half_res else 1, bias=False)\n",
    "            self.parametrized_layers.append(self.shortcut)\n",
    "            self.shortcut_type = '1x1'\n",
    "        else:\n",
    "            self.shortcut_type = 'identity'\n",
    "\n",
    "        for layer in self.parametrized_layers:\n",
    "            init_layer(layer)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        short_out = x if self.shortcut_type == 'identity' else self.shortcut(x)\n",
    "        out = self.C1(x)\n",
    "        out = self.BN1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.C2(out)\n",
    "        out = self.BN2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.C3(out)\n",
    "        out = self.BN3(out)\n",
    "        out = out + short_out\n",
    "\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,list_of_num_layers, list_of_out_dims, num_classes=1000, only_trunk=False ):\n",
    "        # list_of_num_layers specifies number of layers in each stage\n",
    "        # list_of_out_dims specifies number of output channel for each stage\n",
    "        super(ResNet,self).__init__()\n",
    "        self.grads = []\n",
    "        self.fmaps = []\n",
    "        assert len(list_of_num_layers)==4, 'Can have only four stages'\n",
    "        conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                               bias=False)\n",
    "        bn1 = nn.BatchNorm2d(64)\n",
    "        relu = nn.ReLU()\n",
    "        pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        init_layer(conv1)\n",
    "        init_layer(bn1)\n",
    "\n",
    "\n",
    "        trunk = [conv1, bn1, relu, pool1]\n",
    "        indim = 64\n",
    "        for i in range(4):\n",
    "\n",
    "            for j in range(list_of_num_layers[i]):\n",
    "                half_res = (i>=1) and (j==0)\n",
    "                B = block(indim, list_of_out_dims[i], half_res)\n",
    "                trunk.append(B)\n",
    "                indim = list_of_out_dims[i]\n",
    "\n",
    "        self.only_trunk=only_trunk\n",
    "        if not only_trunk:\n",
    "            avgpool = nn.AvgPool2d(7)\n",
    "            trunk.append(avgpool)\n",
    "\n",
    "        self.trunk = nn.Sequential(*trunk)\n",
    "        self.final_feat_dim = indim\n",
    "        if not only_trunk:\n",
    "            self.classifier = nn.Linear(indim, num_classes)\n",
    "            self.classifier.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.trunk(x)\n",
    "        if self.only_trunk:\n",
    "            return out\n",
    "        out = out.view(out.size(0),-1)\n",
    "        scores = self.classifier(out)\n",
    "        return scores, out\n",
    "\n",
    "\n",
    "def ResNet10(num_classes=1000, only_trunk=False):\n",
    "    return ResNet(SimpleBlock, [1,1,1,1],[64,128,256,512], num_classes, only_trunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((300,300)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "train_dataset = datasets.ImageFolder(root='../aligned-data/train',\n",
    "                                           transform=data_transform)\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=20, shuffle=True, \n",
    "                                            num_workers=4)\n",
    "test_dataset = datasets.ImageFolder(root='../aligned-data/test',\n",
    "                                           transform=data_transform)\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                             batch_size=90, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "test_x, test_y = next(iter(test_dataset_loader))\n",
    "test_x, test_y = Variable(test_x), Variable(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet10(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(mdl, X, Y):\n",
    "    # TODO: why can't we call .data.numpy() for train_acc as a whole?\n",
    "    outputs, _ = mdl(X)\n",
    "    max_vals, max_indices = torch.max(outputs,1)\n",
    "    train_acc = (max_indices == Y).sum().data.numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  45.97979009151459\n",
      "Training accuracy:  [0.26304348]\n",
      "Loss:  39.20639443397522\n",
      "Training accuracy:  [0.38043478]\n",
      "Loss:  34.17376083135605\n",
      "Training accuracy:  [0.46086957]\n",
      "Loss:  24.863914370536804\n",
      "Training accuracy:  [0.61086957]\n",
      "Loss:  17.332077592611313\n",
      "Training accuracy:  [0.73695652]\n",
      "Loss:  14.448751628398895\n",
      "Training accuracy:  [0.76956522]\n",
      "Loss:  10.728242874145508\n",
      "Training accuracy:  [0.85217391]\n",
      "Loss:  6.162150984629989\n",
      "Training accuracy:  [0.92391304]\n",
      "Loss:  5.184196501970291\n",
      "Training accuracy:  [0.93695652]\n",
      "Loss:  2.888138484209776\n",
      "Training accuracy:  [0.97391304]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    acc = 0\n",
    "    running_loss = 0.0\n",
    "    test_acc = 0\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=20, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "    \n",
    "    for i, data in enumerate(train_dataset_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, _ = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        max_vals, max_indices = torch.max(outputs, 1)\n",
    "        train_acc = (max_indices == labels).sum().data.numpy()/max_indices.size()[0]\n",
    "        acc += train_acc\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        #if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %\n",
    "            #      (epoch + 1, i + 1, running_loss / 5))\n",
    "        #    running_loss = 0.0\n",
    "        \n",
    "    # Compute test accuracy\n",
    "    #test_acc += calc_accuracy(net, test_x, test_y)\n",
    "\n",
    "    print('Loss: ', running_loss)\n",
    "    print('Training accuracy: ', acc/(len(train_dataset_loader)))\n",
    "    #print('Test accuracy: ', test_acc)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82222222]\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(net, test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(model, data_loader, outfile ):\n",
    "\n",
    "    f = h5py.File(outfile, 'w')\n",
    "    max_count = len(data_loader)*data_loader.batch_size\n",
    "    all_labels = f.create_dataset('all_labels',(max_count,), dtype='i')\n",
    "    all_feats=None\n",
    "    count=0\n",
    "    for i, (x,y) in enumerate(data_loader):\n",
    "        #print(y)\n",
    "        if i%10 == 0:\n",
    "            print('{:d}/{:d}'.format(i, len(data_loader)))\n",
    "        x_var = Variable(x)\n",
    "        scores, feats = model(x_var)\n",
    "        if all_feats is None:\n",
    "            all_feats = f.create_dataset('all_feats', (max_count, feats.size(1)), dtype='f')\n",
    "        all_feats[count:count+feats.size(0),:] = feats.data.cpu().numpy()\n",
    "        all_labels[count:count+feats.size(0)] = y.cpu().numpy()\n",
    "        #print(all_labels[count:count+feats.size(0)])\n",
    "        count = count + feats.size(0)\n",
    "\n",
    "    #print(all_labels)\n",
    "    count_var = f.create_dataset('count', (1,), dtype='i')\n",
    "    count_var[0] = count\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/24\n",
      "10/24\n",
      "20/24\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(root='../novel-data/train',\n",
    "                                           transform=data_transform)\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=20, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "#pics, cls = next(iter(train_dataset_loader))\n",
    "class_names = train_dataset.classes\n",
    "#for x in cls:\n",
    "#    print(x, class_names[x])\n",
    "save_features(net, train_dataset_loader, 'resnet_features.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classes = [0,6,7,8,9,10,11,12,13]\n",
    "novel_classes = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(x, k, niter=1, batchsize=1000):\n",
    "    batchsize = min(batchsize, x.shape[0])\n",
    "\n",
    "    nsamples = x.shape[0]\n",
    "    ndims = x.shape[1]\n",
    "\n",
    "    x2 = np.sum(x**2, axis=1)\n",
    "    centroids = np.random.randn(k, ndims)\n",
    "    centroidnorm = np.sqrt(np.sum(centroids**2, axis=1, keepdims=True))\n",
    "    centroids = centroids / centroidnorm\n",
    "    totalcounts = np.zeros(k)\n",
    "\n",
    "    for i in range(niter):\n",
    "        c2 = np.sum(centroids**2, axis=1,keepdims=True)*0.5\n",
    "        summation = np.zeros((k, ndims))\n",
    "        counts = np.zeros(k)\n",
    "        loss = 0\n",
    "\n",
    "        for j in range(0, nsamples, batchsize):\n",
    "            lastj = min(j+batchsize, nsamples)\n",
    "            batch = x[j:lastj]\n",
    "            m = batch.shape[0]\n",
    "\n",
    "            tmp = np.dot(centroids, batch.T)\n",
    "            tmp = tmp - c2\n",
    "            val = np.max(tmp,0)\n",
    "            labels = np.argmax(tmp,0)\n",
    "            loss = loss + np.sum(np.sum(x2[j:lastj])*0.5 - val)\n",
    "\n",
    "            S = np.zeros((k, m))\n",
    "            S[labels, np.arange(m)] = 1\n",
    "            summation = summation + np.dot(S, batch)\n",
    "            counts = counts + np.sum(S, axis=1)\n",
    "\n",
    "        for j in range(k):\n",
    "            if counts[j]>0:\n",
    "                centroids[j] = summation[j] / counts[j]\n",
    "\n",
    "        totalcounts = totalcounts + counts\n",
    "        for j in range(k):\n",
    "            if totalcounts[j] == 0:\n",
    "                idx = np.random.choice(nsamples)\n",
    "                centroids[j] = x[idx]\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_feats(filehandle, base_classes, cachefile, n_clusters=5):\n",
    "    if os.path.isfile(cachefile):\n",
    "        with open(cachefile, 'rb') as f:\n",
    "            centroids = pickle.load(f)\n",
    "    else:\n",
    "        centroids = []\n",
    "        all_labels = filehandle['all_labels'][...]\n",
    "        all_feats = filehandle['all_feats']\n",
    "\n",
    "        count = filehandle['count'][0]\n",
    "        for j, i in enumerate(base_classes):\n",
    "            print('Clustering class {:d}:{:d}'.format(j,i))\n",
    "            idx = np.where(all_labels==i)[0]\n",
    "            idx = idx[idx<count]\n",
    "            X = all_feats[idx,:]\n",
    "            # use a reimplementation of torch kmeans for reproducible results\n",
    "            # TODO: Figure out why this is important\n",
    "            centroids_this = kmeans(X, n_clusters, 20)\n",
    "            centroids.append(centroids_this)\n",
    "        with open(cachefile, 'wb') as f:\n",
    "            pickle.dump(centroids, f)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering class 0:0\n",
      "Clustering class 1:6\n",
      "Clustering class 2:7\n",
      "Clustering class 3:8\n",
      "Clustering class 4:9\n",
      "Clustering class 5:10\n",
      "Clustering class 6:11\n",
      "Clustering class 7:12\n",
      "Clustering class 8:13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with h5py.File('resnet_features.hdf5', 'r') as features_file:\n",
    "    centroids = cluster_feats(features_file, base_classes, 'centroids.pkl', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference_vectors(c_i):\n",
    "    diff_i = c_i[:,np.newaxis,:] - c_i[np.newaxis,:,:]\n",
    "    diff_i = diff_i.reshape((-1, diff_i.shape[2]))\n",
    "    diff_i_norm = np.sqrt(np.sum(diff_i**2,axis=1, keepdims=True))\n",
    "    diff_i = diff_i / (diff_i_norm + 0.00001)\n",
    "    return diff_i\n",
    "\n",
    "def mine_analogies(centroids):\n",
    "    n_clusters = centroids[0].shape[0]\n",
    "\n",
    "    analogies = np.zeros((n_clusters*n_clusters*len(centroids),4), dtype=int)\n",
    "    analogy_scores = np.zeros(analogies.shape[0])\n",
    "    start=0\n",
    "\n",
    "    I, J = np.unravel_index(np.arange(n_clusters**2), (n_clusters, n_clusters))\n",
    "    # for every class\n",
    "    for i, c_i in enumerate(centroids):\n",
    "\n",
    "        # get normalized difference vectors between cluster centers\n",
    "        diff_i = get_difference_vectors(c_i)\n",
    "        diff_i_t = torch.Tensor(diff_i)\n",
    "\n",
    "\n",
    "        bestdots = np.zeros(diff_i.shape[0])\n",
    "        bestdotidx = np.zeros((diff_i.shape[0],2),dtype=int)\n",
    "\n",
    "        # for every other class\n",
    "        for j, c_j in enumerate(centroids):\n",
    "            if i==j:\n",
    "                continue\n",
    "            print(i,j)\n",
    "\n",
    "            # get normalized difference vectors\n",
    "            diff_j = get_difference_vectors(c_j)\n",
    "            diff_j = torch.Tensor(diff_j)\n",
    "\n",
    "            #compute cosine distance and take the maximum\n",
    "            dots = diff_i_t.mm(diff_j.transpose(0,1))\n",
    "            maxdots, argmaxdots = dots.max(1)\n",
    "            maxdots = maxdots.cpu().numpy().reshape(-1)\n",
    "            argmaxdots = argmaxdots.cpu().numpy().reshape(-1)\n",
    "\n",
    "            # if maximum is better than best seen so far, update\n",
    "            betteridx = maxdots>bestdots\n",
    "            bestdots[betteridx] = maxdots[betteridx]\n",
    "            bestdotidx[betteridx,0] = j*n_clusters + I[argmaxdots[betteridx]]\n",
    "            bestdotidx[betteridx,1] = j*n_clusters + J[argmaxdots[betteridx]]\n",
    "\n",
    "\n",
    "        # store discovered analogies\n",
    "        stop = start+diff_i.shape[0]\n",
    "        analogies[start : stop,0]=i*n_clusters + I\n",
    "        analogies[start : stop,1]=i*n_clusters + J\n",
    "        analogies[start : stop,2:] = bestdotidx\n",
    "        analogy_scores[start : stop] = bestdots\n",
    "        start = stop\n",
    "\n",
    "    #prune away trivial analogies\n",
    "    good_analogies = (analogy_scores>0) & (analogies[:,0]!=analogies[:,1]) & (analogies[:,2]!=analogies[:,3])\n",
    "    return analogies[good_analogies,:], analogy_scores[good_analogies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "1 0\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "2 0\n",
      "2 1\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 7\n",
      "6 8\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 8\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "8 5\n",
      "8 6\n",
      "8 7\n"
     ]
    }
   ],
   "source": [
    "analogies, analogy_scores = mine_analogies(centroids)\n",
    "np.save('analogies.npy', analogies.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(filehandle, base_classes, cachefile, networkfile, total_num_classes=14, lr=0.1, wd=0.0001, momentum=0.9, batchsize=30, niter=300):\n",
    "    # either use pre-existing classifier or train one\n",
    "    all_labels = filehandle['all_labels'][...]\n",
    "    all_labels = all_labels.astype(int)\n",
    "    all_feats = filehandle['all_feats']\n",
    "    base_class_ids = np.where(np.in1d(all_labels, base_classes))[0]\n",
    "    #print(base_class_ids)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    model = nn.Linear(all_feats[0].size, total_num_classes)\n",
    "    if os.path.isfile(cachefile):\n",
    "        tmp = torch.load(cachefile)\n",
    "        model.load_state_dict(tmp)\n",
    "    elif os.path.isfile(networkfile):\n",
    "        tmp = torch.load(networkfile)\n",
    "        if 'module.classifier.bias' in tmp['state']:\n",
    "            state_dict = {'weight':tmp['state']['module.classifier.weight'], 'bias':tmp['state']['module.classifier.bias']}\n",
    "        else:\n",
    "            model = nn.Linear(all_feats[0].size, total_num_classes, bias=False).cuda()\n",
    "            state_dict = {'weight':tmp['state']['module.classifier.weight']}\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=wd, dampening=0)\n",
    "        for i in range(niter):\n",
    "            optimizer.zero_grad()\n",
    "            idx = np.sort(np.random.choice(base_class_ids, batchsize, replace=False))\n",
    "            F = all_feats[idx,:]\n",
    "            F = Variable(torch.Tensor(F))\n",
    "            L = Variable(torch.LongTensor(all_labels[idx]))\n",
    "            S = model(F)\n",
    "            loss_val = loss(S, L)\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                print('Classifier training {:d}: {:f}'.format(i, loss_val.data[0]))\n",
    "        #torch.save(model.state_dict(), cachefile)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier training 0: 2.393940\n",
      "Classifier training 100: 0.035842\n",
      "Classifier training 200: 0.000738\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('resnet_features.hdf5', 'r') as features_file:\n",
    "    classification_model = train_classifier(features_file, base_classes, 'classifier.pkl', 'random.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy regressor train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalogyRegressor(nn.Module):\n",
    "    def __init__(self, featdim, innerdim=512):\n",
    "        super(AnalogyRegressor,self).__init__()\n",
    "        self.featdim = featdim\n",
    "        self.innerdim = innerdim\n",
    "        self.fc1 = nn.Linear(featdim*3, innerdim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(innerdim, innerdim)\n",
    "        self.fc3 = nn.Linear(innerdim, featdim)\n",
    "\n",
    "    def forward(self, a,c,d):\n",
    "        x = torch.cat((a,c,d), dim=1)\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def train_analogy_regressor(analogies, centroids, base_classes, trained_classifier, lr=0.1, wt=10, niter=1000, step_after=5000, batchsize=40, momentum=0.9, wd=0.0001):\n",
    "    # pre-permute analogies\n",
    "    permuted_analogies = analogies[np.random.permutation(analogies.shape[0])]\n",
    "\n",
    "    # create model and init\n",
    "    featdim = centroids[0].shape[1]\n",
    "    model = AnalogyRegressor(featdim)\n",
    "    model = model\n",
    "    trained_classifier = trained_classifier\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=wd, dampening=momentum)\n",
    "    loss_1 = nn.CrossEntropyLoss()\n",
    "    loss_2 = nn.MSELoss()\n",
    "\n",
    "\n",
    "    num_clusters_per_class = centroids[0].shape[0]\n",
    "    centroid_labels = (np.array(base_classes).reshape((-1,1)) * np.ones((1, num_clusters_per_class))).reshape(-1)\n",
    "    concatenated_centroids = np.concatenate(centroids, axis=0)\n",
    "\n",
    "\n",
    "    start=0\n",
    "    avg_loss_1 = avg_loss_2 = count = 0.0\n",
    "    for i in range(niter):\n",
    "        # get current batch of analogies\n",
    "        stop = min(start+batchsize, permuted_analogies.shape[0])\n",
    "        #print(start+batchsize, permuted_analogies.shape[0])\n",
    "        to_train = permuted_analogies[start:stop,:]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # analogy is A:B :: C:D, goal is to predict B from A, C, D\n",
    "        # Y is the class label of B (and A)\n",
    "        A = concatenated_centroids[to_train[:,0]]\n",
    "        B = concatenated_centroids[to_train[:,1]]\n",
    "        C = concatenated_centroids[to_train[:,2]]\n",
    "        D = concatenated_centroids[to_train[:,3]]\n",
    "        Y = centroid_labels[to_train[:,1]]\n",
    "\n",
    "        A = Variable(torch.Tensor(A))\n",
    "        B = Variable(torch.Tensor(B))\n",
    "        C = Variable(torch.Tensor(C))\n",
    "        D = Variable(torch.Tensor(D))\n",
    "        Y = Variable(torch.LongTensor(Y.astype(int)))\n",
    "\n",
    "        Bhat = model(A,C,D)\n",
    "\n",
    "        lossval_2 = loss_2(Bhat, B) # simple mean squared error loss\n",
    "\n",
    "        # classification loss\n",
    "        predicted_classprobs = trained_classifier(Bhat)\n",
    "        lossval_1 = loss_1(predicted_classprobs, Y)\n",
    "        loss = lossval_1 + wt * lossval_2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss_1 = avg_loss_1 + lossval_1.data[0]\n",
    "        avg_loss_2 = avg_loss_2 + lossval_2.data[0]\n",
    "        count = count+1.0\n",
    "\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('{:d} : {:f}, {:f}, {:f}'.format(i, avg_loss_1/count, avg_loss_2/count, count))\n",
    "            avg_loss_1 = avg_loss_2 = count = 0.0\n",
    "\n",
    "        if (i+1) % step_after == 0:\n",
    "            lr = lr / 10.0\n",
    "            print(lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        start = stop\n",
    "        if start==permuted_analogies.shape[0]:\n",
    "            start=0\n",
    "\n",
    "    return dict(model_state=model.state_dict(), concatenated_centroids=torch.Tensor(concatenated_centroids),\n",
    "            num_base_classes=len(centroids), num_clusters_per_class=num_clusters_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 3.180349, 0.385121, 1.000000\n",
      "50 : 2.644247, 0.285706, 50.000000\n",
      "100 : 0.247157, 0.170330, 50.000000\n",
      "150 : 0.019489, 0.112760, 50.000000\n",
      "200 : 0.007013, 0.092660, 50.000000\n",
      "250 : 0.005519, 0.086101, 50.000000\n",
      "300 : 0.004374, 0.081732, 50.000000\n",
      "350 : 0.003700, 0.079154, 50.000000\n",
      "400 : 0.003070, 0.076126, 50.000000\n",
      "450 : 0.002545, 0.072913, 50.000000\n",
      "500 : 0.002269, 0.071320, 50.000000\n",
      "550 : 0.002046, 0.069961, 50.000000\n",
      "600 : 0.001725, 0.067859, 50.000000\n",
      "650 : 0.001580, 0.066712, 50.000000\n",
      "700 : 0.001457, 0.065237, 50.000000\n",
      "750 : 0.001356, 0.064322, 50.000000\n",
      "800 : 0.001260, 0.063657, 50.000000\n",
      "850 : 0.001119, 0.062718, 50.000000\n",
      "900 : 0.001021, 0.061777, 50.000000\n",
      "950 : 0.000967, 0.061261, 50.000000\n"
     ]
    }
   ],
   "source": [
    "generator = train_analogy_regressor(analogies, centroids, base_classes, classification_model, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_generator(generator):\n",
    "    featdim = generator['concatenated_centroids'].size(1)\n",
    "    model = AnalogyRegressor(featdim)\n",
    "    model.load_state_dict(generator['model_state'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_generate(feats, labels, generator, gen_model, max_per_label):\n",
    "    # generate till there are at least max_per_label examples for each label\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(unique_labels)\n",
    "    generations_needed = []\n",
    "    generator['concatenated_centroids'] = generator['concatenated_centroids']\n",
    "    for k, lab in enumerate(unique_labels):\n",
    "        # for each label\n",
    "        idx = np.where(labels==lab)[0]\n",
    "        print(idx.size)\n",
    "        # generate this many examples:\n",
    "        num_to_gen = max(max_per_label - idx.size,0)\n",
    "        \n",
    "        if num_to_gen>0:\n",
    "            # choose a random seed\n",
    "            seed = np.random.choice(idx, num_to_gen)\n",
    "            # and a random base class\n",
    "            base_class = np.random.choice(generator['num_base_classes'], num_to_gen)\n",
    "            # and two random centroids from this base class\n",
    "            c_c = np.random.choice(generator['num_clusters_per_class'], num_to_gen)\n",
    "            c_d = np.random.choice(generator['num_clusters_per_class'], num_to_gen)\n",
    "\n",
    "            centroid_ids_c = base_class*generator['num_clusters_per_class'] + c_c\n",
    "            centroid_ids_d = base_class*generator['num_clusters_per_class'] + c_d\n",
    "            # add to list of things to generate\n",
    "            generations_needed.append( np.concatenate((seed.reshape((-1,1)), centroid_ids_c.reshape((-1,1)), centroid_ids_d.reshape((-1,1))),axis=1))\n",
    "\n",
    "    if len(generations_needed)>0:\n",
    "        generations_needed = np.concatenate(generations_needed, axis=0)\n",
    "        gen_feats = np.zeros((generations_needed.shape[0],feats.shape[1]))\n",
    "        gen_labels = np.zeros(generations_needed.shape[0])\n",
    "\n",
    "\n",
    "        # batch up the generations\n",
    "        batchsize=20\n",
    "        for start in range(0, generations_needed.shape[0], batchsize):\n",
    "            stop = min(start + batchsize, generations_needed.shape[0])\n",
    "            g_idx = generations_needed[start:stop,:]\n",
    "            A = Variable(torch.Tensor(feats[g_idx[:,0],:]))\n",
    "            C = Variable(torch.Tensor(generator['concatenated_centroids'][g_idx[:,1],:]))\n",
    "            D = Variable(torch.Tensor(generator['concatenated_centroids'][g_idx[:,2],:]))\n",
    "            F = gen_model(A,C,D).cpu().data.numpy().copy()\n",
    "            gen_feats[start:stop,:] = F\n",
    "            print(np.linalg.norm(F-feats[g_idx[:,0],:]), np.linalg.norm(F), np.linalg.norm(feats[g_idx[:,0],:]))\n",
    "            gen_labels[start:stop] = labels[g_idx[:,0]]\n",
    "\n",
    "        return np.concatenate((feats, gen_feats), axis=0), np.concatenate((labels, gen_labels), axis=0)\n",
    "    else:\n",
    "        return feats, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "33.641155 53.51277 65.73723\n",
      "29.362307 57.32475 60.44626\n",
      "34.843 55.973732 68.76972\n",
      "25.34141 48.047695 56.049313\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('resnet_features.hdf5', 'r') as filehandle:\n",
    "    all_labels = filehandle['all_labels'][...]\n",
    "    #all_labels = all_labels.astype(int)\n",
    "    all_feats = filehandle['all_feats']\n",
    "    novel_class_ids = np.where(np.in1d(all_labels, novel_classes))[0]\n",
    "    novel_features = all_feats[novel_class_ids, :]\n",
    "    novel_labels = all_labels[novel_class_ids]\n",
    "    gen_model = init_generator(generator)\n",
    "    gen_features, gen_labels = do_generate(novel_features, novel_labels, generator, gen_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/7\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.ImageFolder(root='../novel-data/test',\n",
    "                                           transform=data_transform)\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                             batch_size=20, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "save_features(net, test_dataset_loader, 'resnet_features_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_class_accuracy(mdl, X, Y):\n",
    "    # TODO: why can't we call .data.numpy() for train_acc as a whole?\n",
    "    outputs = mdl(X)\n",
    "    max_vals, max_indices = torch.max(outputs,1)\n",
    "    acc_val = 0\n",
    "    for i in range(len(Y)):\n",
    "        if (max_indices[i].data == Y[i].data).numpy():\n",
    "            acc_val += 1\n",
    "        else:\n",
    "            print(Y[i], max_indices[i])\n",
    "    print(acc_val)\n",
    "    #acc = (max_indices == Y).sum().data.numpy()/max_indices.size()[0]\n",
    "    #print((max_indices == Y))\n",
    "    return acc_val/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_novel_classifier(features, labels, lr=0.01, wd=0.0001, momentum=0.9):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    model = nn.Linear(features[0].size, 6)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=wd, dampening=0)\n",
    "    for i in range(300):\n",
    "        optimizer.zero_grad()\n",
    "        #idx = np.sort(np.random.choice(np.arange(100), 20, replace=False))\n",
    "        #print(idx)\n",
    "        #F = features[idx,:]\n",
    "        F = Variable(torch.Tensor(features))\n",
    "        L = Variable(torch.LongTensor(labels))\n",
    "        S = model(F)\n",
    "        #print(calc_class_accuracy(model, F, L))\n",
    "        loss_val = loss(S, L)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('resnet_features.hdf5', 'r') as filehandle:\n",
    "    all_labels = filehandle['all_labels'][...]\n",
    "    all_labels = all_labels.astype(int)\n",
    "    all_feats = filehandle['all_feats']\n",
    "    novel_class_ids = np.where(np.in1d(all_labels, novel_classes))[0]\n",
    "    idx = np.sort(np.random.choice(novel_class_ids, 25, replace=False))\n",
    "    my_feat = all_feats[idx,:]\n",
    "    my_labels = all_labels[idx]\n",
    "    novel_classifier = train_base_novel_classifier(gen_features, gen_labels)\n",
    "    F = Variable(torch.Tensor(my_feat))\n",
    "    L = Variable(torch.LongTensor(my_labels))\n",
    "    print(calc_class_accuracy(novel_classifier, F, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "14\n",
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('resnet_features_test.hdf5', 'r') as filehandle:\n",
    "    all_labels = filehandle['all_labels'][...]\n",
    "    all_labels = all_labels.astype(int)\n",
    "    all_feats = filehandle['all_feats']\n",
    "    base_class_ids = np.where(np.in1d(all_labels, base_classes))[0]\n",
    "    #print((base_class_ids))\n",
    "    novel_class_ids = np.where(np.in1d(all_labels, novel_classes))[0]\n",
    "    #print(novel_class_ids)\n",
    "    np.random.seed(42)\n",
    "    idx = np.sort(np.random.choice(novel_class_ids, 49, replace=False))\n",
    "    #print(idx)\n",
    "    F = all_feats[idx,:]\n",
    "    F = Variable(torch.Tensor(F))\n",
    "    L = Variable(torch.LongTensor(all_labels[idx]))\n",
    "    print(calc_class_accuracy(novel_classifier, F, L))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
